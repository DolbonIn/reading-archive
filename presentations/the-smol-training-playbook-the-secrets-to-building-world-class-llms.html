<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Smol Training Playbook: Presentation</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700;900&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Inter', sans-serif;
      background-color: #f8f9fa;
    }
    .slide {
      display: none;
      min-height: 85vh;
      align-items: center;
      justify-content: center;
      flex-direction: column;
      padding: 2rem;
    }
    .slide.active {
      display: flex;
    }
    .slide-container {
        width: 100%;
        max-width: 1100px;
        background-color: white;
        border-radius: 1.5rem;
        padding: 4rem;
        box-shadow: 0 20px 25px -5px rgb(0 0 0 / 0.1), 0 8px 10px -6px rgb(0 0 0 / 0.1);
        border: 1px solid #e9ecef;
    }
    .slide-part-title {
      font-size: 1.2rem;
      font-weight: 700;
      color: #6c757d;
      margin-bottom: 8px;
    }
    .slide-title {
      font-size: 2.8rem;
      font-weight: 900;
      color: #212529;
      margin-bottom: 25px;
      line-height: 1.3;
    }
    .slide-subtitle {
      font-size: 1.4rem;
      font-weight: 500;
      color: #495057;
      margin-bottom: 35px;
      line-height: 1.6;
    }
    .slide-content {
      font-size: 1.1rem;
      line-height: 1.9;
      color: #343a40;
    }
    .highlight {
      background-color: #ffd60a;
      padding: 0 0.25em;
      border-radius: 0.25rem;
    }
    .btn {
      padding: 12px 28px;
      border-radius: 8px;
      font-weight: 700;
      transition: all 0.2s ease;
      cursor: pointer;
      border: none;
      box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
    }
    .btn-primary {
      background-color: #0077b6;
      color: white;
    }
    .btn-primary:hover {
      background-color: #023e8a;
    }
    .btn-secondary {
      background-color: #e9ecef;
      color: #343a40;
    }
    .btn-secondary:hover {
      background-color: #dee2e6;
    }
    .progress-bar-container {
      position: fixed;
      bottom: 0;
      left: 0;
      width: 100%;
      padding: 20px 40px;
      background-color: rgba(255, 255, 255, 0.9);
      backdrop-filter: blur(8px);
      border-top: 1px solid #dee2e6;
      z-index: 10;
    }
    .progress-bar {
      width: 100%;
      background-color: #e9ecef;
      border-radius: 9999px;
      height: 8px;
      margin-bottom: 15px;
    }
    .progress {
      background-color: #0077b6;
      height: 100%;
      border-radius: 9999px;
      transition: width 0.3s ease;
    }
    ul {
        list-style-type: disc;
        padding-left: 2rem;
    }
    li {
        margin-bottom: 0.75rem;
    }
  </style>
</head>
<body class="flex flex-col items-center justify-center p-4 md:p-8 pb-32">

  <!-- Slides Container: Add your slides here -->
  <div id="slides-container">

    <!-- Slide 1: Title -->
    <div class="slide active">
        <div class="slide-container text-center">
            <div class="text-7xl mb-8">üöÄ</div>
            <h1 class="text-5xl md:text-6xl font-black text-gray-900 mb-4">The Smol Training Playbook</h1>
            <p class="text-xl md:text-2xl text-gray-700">The Secrets to Building <span class="highlight">World-Class LLMs</span></p>
            <p class="mt-8 text-lg text-gray-600">A practical journey through the challenges, decisions, and messy reality behind training state-of-the-art language models.</p>
        </div>
    </div>

    <!-- Slide 2: Table of Contents -->
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">üó∫Ô∏è Table of Contents</h2>
            <div class="slide-content text-lg space-y-3">
                <p><b>1. Introduction:</b> The messy reality of LLM training.</p>
                <p><b>2. The Training Compass:</b> A guide to deciding <span class="highlight">Why, What, and How</span> to train.</p>
                <p><b>3. Architecture & Ablations:</b> Designing your model from the ground up.</p>
                <p><b>4. Optimizers & Hyperparameters:</b> Tuning the engine of your training run.</p>
                <p><b>5. The Art of Data Curation:</b> Crafting the perfect curriculum for your model.</p>
                <p><b>6. The Training Marathon:</b> Navigating the challenges of a long run.</p>
                <p><b>7. Post-Training:</b> From a base model to a helpful assistant.</p>
                <p><b>8. Infrastructure:</b> The unsung hero of LLM training.</p>
            </div>
        </div>
    </div>
    
    <!-- SECTION: INTRODUCTION -->
    <div class="slide">
        <div class="slide-container">
            <p class="slide-part-title">Part 1: Introduction</p>
            <h2 class="slide-title">Beyond the Polished Paper üìú</h2>
            <p class="slide-subtitle">Published research makes LLM training look straightforward. The reality is <span class="highlight">messier, more iterative, and full of dead ends.</span></p>
            <div class="slide-content">
                <p>This isn't an ordinary blog post. It's an untangling of the spiderweb of decisions, discoveries, and failures that lead to world-class language models.</p>
                <p class="mt-4">We'll look behind the scenes of training <b>SmolLM3</b>, a 3B multilingual reasoning model, and share not just the final recipe, but the entire chaotic journey.</p>
            </div>
        </div>
    </div>

    <!-- SECTION: THE TRAINING COMPASS -->
    <div class="slide">
        <div class="slide-container text-center">
            <p class="slide-part-title">Part 2: The Training Compass</p>
            <h2 class="slide-title">üß≠ Why ‚Üí What ‚Üí How</h2>
            <p class="slide-subtitle">A systematic framework for making decisions before you burn through your VC money.</p>
        </div>
    </div>

    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">The First Question: <span class="highlight">Why</span> Train?</h2>
            <p class="slide-subtitle">Before diving into technical details, we must answer the most fundamental question: <b>Should we even be training this model?</b></p>
            <div class="slide-content grid grid-cols-1 md:grid-cols-2 gap-8">
                <div>
                    <h3 class="font-bold text-lg text-red-600">Bad Reasons to Train</h3>
                    <ul class="mt-2 text-red-800">
                        <li>"We have compute available." (That's a resource, not a goal)</li>
                        <li>"Everyone else is doing it." (That's peer pressure, not strategy)</li>
                        <li>"We want the best model possible." (Not specific enough to guide decisions)</li>
                    </ul>
                </div>
                <div>
                    <h3 class="font-bold text-lg text-green-600">Good Reasons to Train</h3>
                     <ul class="mt-2 text-green-800">
                        <li><b>Research:</b> You have a clearly defined research question to investigate.</li>
                        <li><b>Production:</b> Existing models can't handle your specific domain or deployment constraints.</li>
                        <li><b>Strategic Open-Source:</b> You've identified a specific gap in the open-source ecosystem you can fill.</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Decision Flowchart: To Train or Not to Train? ü§î</h2>
             <div class="slide-content">
                <p>Before starting a massive pretraining project, follow this thought process:</p>
                <ol class="list-decimal pl-6 mt-4 space-y-4">
                    <li><b>Can existing models handle your use case with prompting?</b>
                        <br>‚û°Ô∏è If YES, don't train. Use existing models.
                    </li>
                    <li><b>If prompting isn't enough, can fine-tuning solve your problem?</b>
                        <br>This includes post-training or continual pretraining on a smaller scale.
                        <br>‚û°Ô∏è If YES, don't train from scratch. Fine-tune instead.
                    </li>
                     <li><b>If fine-tuning cannot solve your problem, you may need to train.</b>
                        <br>‚û°Ô∏è If YES, proceed with a clear goal: <span class="highlight">Research</span>, <span class="highlight">Production</span>, or <span class="highlight">Strategic Open-Source</span>.
                    </li>
                </ol>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Translating <span class="highlight">"Why"</span> into <span class="highlight">"What"</span></h2>
            <p class="slide-subtitle">Once you know your purpose, you can define the model's characteristics.</p>
            <div class="slide-content space-y-4">
                <p>Your goal directly informs the model architecture, size, and data mixture.</p>
                <div class="p-6 bg-gray-50 border border-gray-200 rounded-lg">
                    <p>üéØ <b>Goal:</b> Fast model for on-device use.<br>
                    ‚û°Ô∏è <b>What:</b> Small, efficient dense model.</p>
                </div>
                 <div class="p-6 bg-gray-50 border border-gray-200 rounded-lg">
                    <p>üåç <b>Goal:</b> Multilingual model.<br>
                    ‚û°Ô∏è <b>What:</b> Large tokenizer vocabulary.</p>
                </div>
                 <div class="p-6 bg-gray-50 border border-gray-200 rounded-lg">
                    <p>üìë <b>Goal:</b> Super long context.<br>
                    ‚û°Ô∏è <b>What:</b> Hybrid architecture (e.g., with SSM/Mamba).</p>
                </div>
            </div>
        </div>
    </div>

    <!-- SECTION: Architecture & Ablations -->
     <div class="slide">
        <div class="slide-container text-center">
            <p class="slide-part-title">Part 3: Architecture & Ablations</p>
            <h2 class="slide-title">üèóÔ∏è Every Big Model Starts with a Small Ablation</h2>
            <p class="slide-subtitle">Systematically testing ideas to build a robust architecture.</p>
        </div>
    </div>

    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Choosing Your <span class="highlight">Baseline</span></h2>
            <p class="slide-subtitle">Don't reinvent the wheel. Start from a proven foundation.</p>
            <div class="slide-content">
                <p>Every successful model builds on prior work. Good architectures and training setups take years of iteration across many organizations. Starting fresh means rediscovering every problem yourself.</p>
                <div class="mt-8 p-6 bg-blue-50 border border-blue-200 rounded-lg">
                  <h3 class="font-bold text-lg text-blue-800">What makes a good baseline?</h3>
                  <ul class="mt-2">
                    <li>‚úÖ <b>Matches your constraints:</b> Aligns with your deployment target and use case.</li>
                    <li>‚úÖ <b>Proven at scale:</b> Has completed multi-trillion token runs.</li>
                    <li>‚úÖ <b>Well-documented:</b> Known hyperparameters that are proven to work.</li>
                    <li>‚úÖ <b>Framework support:</b> Supported by your chosen training and inference frameworks.</li>
                  </ul>
                </div>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
          <h2 class="slide-title">The Discipline of <span class="highlight">Derisking</span> üî¨</h2>
          <p class="slide-subtitle">Never change anything unless you've tested that it helps.</p>
          <div class="slide-content">
            <p>Every architectural change carries risk. It might boost performance, tank it, or do nothing while wasting compute. The process of derisking involves systematically testing changes against your baseline.</p>
            <div class="mt-8 p-6 bg-yellow-50 border border-yellow-300 rounded-lg">
                <h3 class="font-bold text-lg">üí° Strategic Experimentation</h3>
                <p class="mt-2">Knowing how to run experiments isn't enough if you don't know which experiments are worth running. Before testing any modification, ask yourself two questions:</p>
                <ul class="mt-4">
                    <li>1. Will this help my specific <b>use case</b>?</li>
                    <li>2. Will this optimize my <b>training</b> (speed, stability, efficiency)?</li>
                </ul>
                 <p class="mt-2 font-semibold">If a modification doesn't clearly address either question, skip it.</p>
            </div>
          </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Picking a Training Framework</h2>
            <p class="slide-subtitle">Balancing features, stability, and performance.</p>
            <div class="slide-content">
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 text-center">
                    <div>
                        <h3 class="font-bold text-lg">Mature & Battle-Tested</h3>
                        <p class="mt-2 text-gray-600">(e.g., Megatron-LM, DeepSpeed)</p>
                        <p class="mt-4">‚úÖ <b>Pros:</b> Extensive features, highly optimized, proven in many large models.</p>
                        <p class="mt-2">‚ùå <b>Cons:</b> Complex codebases, hard to modify, steep learning curve.</p>
                    </div>
                    <div>
                        <h3 class="font-bold text-lg">Modern & Lean</h3>
                        <p class="mt-2 text-gray-600">(e.g., TorchTitan, nanotron)</p>
                        <p class="mt-4">‚úÖ <b>Pros:</b> Simpler to navigate, easier to extend, great for rapid experimentation.</p>
                        <p class="mt-2">‚ùå <b>Cons:</b> Newer, less battle-tested, may be less stable or missing features.</p>
                    </div>
                </div>
                <div class="mt-8 p-4 bg-gray-50 rounded-lg text-center">
                    <p><b>Your choice depends on team expertise, target features, and timeline.</b> For quick experiments, simpler codebases often win.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Core Architecture: Attention üß†</h2>
            <p class="slide-subtitle">The attention mechanism is the main bottleneck at inference. Optimizing it is crucial.</p>
            <div class="slide-content grid grid-cols-1 md:grid-cols-2 gap-8">
                <div>
                    <h3 class="font-bold text-lg">Multi-Head Attention (MHA)</h3>
                    <p>The original standard. Each head has its own Key (K) and Value (V) projections.</p>
                    <p class="mt-2 text-red-600"><b>Problem:</b> The KV-Cache grows linearly with sequence length, consuming huge amounts of GPU memory.</p>
                </div>
                <div>
                    <h3 class="font-bold text-lg">Grouped-Query Attention (GQA)</h3>
                    <p>A modern alternative. Groups of query heads share a single K and V projection.</p>
                    <p class="mt-2 text-green-600"><b>Benefit:</b> Drastically reduces KV-Cache size while preserving most of the performance of MHA. It's a solid, efficient choice.</p>
                </div>
            </div>
             <div class="mt-6 text-center">
                <p>Other variants like <b>Multi-Query Attention (MQA)</b> and <b>Multi-Latent Attention (MLA)</b> offer different trade-offs between performance and efficiency.</p>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Attention Ablation: <span class="highlight">GQA Beats MHA</span></h2>
            <p class="slide-subtitle">Ablation results show GQA configurations roughly match MHA performance while being more efficient.</p>
            <div class="slide-content">
                <ul class="space-y-4">
                    <li>üìâ <b>Underperforming:</b> Multi-Query Attention (MQA) and GQA with too few KV heads (e.g., 1 or 2) underperform significantly. They are too restrictive.</li>
                    <li>ü§ù <b>The Sweet Spot:</b> GQA configurations with a reasonable number of KV head groups (e.g., ratios of 4:1 or 8:1 query heads to KV heads) match the performance of full MHA.</li>
                    <li>üèÜ <b>Conclusion:</b> GQA is a solid alternative to MHA. It preserves performance while being much more efficient at inference. <span class="highlight">For SmolLM3, GQA with 4 groups was chosen.</span></li>
                </ul>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
          <h2 class="slide-title">Handling Context: Document Packing üì¶</h2>
          <p class="slide-subtitle">How to efficiently feed variable-length documents into fixed-length training sequences.</p>
          <div class="slide-content grid grid-cols-1 md:grid-cols-2 gap-8">
            <div>
              <h3 class="font-bold text-lg">Causal Masking (The Default)</h3>
              <p>Concatenate multiple documents to fill the context window. Tokens can attend to all previous tokens, <span class="text-red-600">even those from different documents.</span></p>
              <p class="mt-2"><b>Downside:</b> Introduces noise from unrelated content, which can degrade performance.</p>
            </div>
            <div>
              <h3 class="font-bold text-lg">Intra-Document Masking (The Fix)</h3>
              <p>Modify the attention mask so tokens can only attend to previous tokens <span class="text-green-600">within the same document.</span></p>
              <p class="mt-2"><b>Upside:</b> Reduces noise and becomes crucial for stability and speed when scaling to very long sequences.</p>
            </div>
          </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Positional Encodings: <span class="highlight">RoPE vs. NoPE</span></h2>
            <p class="slide-subtitle">Teaching the model the order of tokens in a sequence.</p>
            <div class="slide-content grid grid-cols-1 md:grid-cols-2 gap-8">
                <div>
                    <h3 class="font-bold text-lg">Rotary Position Embedding (RoPE)</h3>
                    <p>The dominant technique. Encodes position by rotating query and key vectors. Excellent for in-context performance.</p>
                    <p class="mt-2 text-red-600"><b>Limitation:</b> Struggles to generalize to sequences longer than those seen during training.</p>
                </div>
                <div>
                    <h3 class="font-bold text-lg">No Position Embedding (NoPE)</h3>
                    <p>A hybrid approach (also called RNoPE). Alternates RoPE layers with layers that have no explicit positional encoding.</p>
                    <p class="mt-2 text-green-600"><b>Benefit:</b> Maintains strong short-context performance while gaining better long-context capabilities. A great choice for long-context models.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Improving Stability üõ°Ô∏è</h2>
            <p class="slide-subtitle">Simple techniques to prevent loss spikes and keep training stable at scale.</p>
            <div class="slide-content space-y-4">
                <p><b>Z-loss:</b> A regularization technique that prevents the final output logits from growing too large. Helpful, but not always necessary for smaller models.</p>
                <p><b>No Weight Decay on Embeddings:</b> Excluding embedding layers from weight decay can improve stability by preventing their norms from decreasing too much, which can lead to large gradients.</p>
                <p><b>QK-norm:</b> Applies layer normalization to query and key vectors before computing attention. Prevents attention logits from becoming too large but can sometimes hurt long-context tasks.</p>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Architecture Decision Tree üå≥</h2>
            <p class="slide-subtitle">Which base architecture is right for you?</p>
            <div class="slide-content space-y-4">
                <div>
                    <h3 class="font-bold text-lg">1. Where will it run?</h3>
                    <p>If on <span class="highlight">memory-constrained environments</span> (edge/phones), choose <b>Dense</b>. Otherwise, if you have more memory, proceed.</p>
                </div>
                <div>
                    <h3 class="font-bold text-lg">2. What's your team's expertise?</h3>
                    <p>If it's your <span class="highlight">first LLM training</span>, stick with <b>Dense</b>. If you are very experienced and want the best performance per compute, consider <b>MoE or Hybrid</b>.</p>
                </div>
                 <div>
                    <h3 class="font-bold text-lg">3. What's your timeline?</h3>
                    <p>If you have a <span class="highlight">tight timeline</span> on a proven path, use <b>Dense</b>. If your timeline is flexible and open to exploration, consider <b>MoE or Hybrid</b>.</p>
                </div>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">The Tokenizer: The Unsung Hero ü¶∏</h2>
            <p class="slide-subtitle">The translator between human language and the model's mathematical world.</p>
            <div class="slide-content">
                <p>The choice of tokenizer is one of the most underrated but critical decisions.</p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mt-6">
                    <div>
                        <h3 class="font-bold text-lg">Key Decisions</h3>
                        <ul>
                            <li><b>Languages & Domains:</b> What languages (English, Chinese, etc.) and domains (code, math) must it support?</li>
                            <li><b>Vocabulary Size:</b> Larger vocabs compress text more efficiently but increase model size. Multilingual models often need 100k+.</li>
                        </ul>
                    </div>
                    <div>
                        <h3 class="font-bold text-lg">How to Evaluate</h3>
                        <ul>
                            <li><b>Fertility:</b> Average tokens per word. Lower is better.</li>
                            <li><b>Continued Words:</b> Percentage of words split into multiple tokens. Lower is better.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- SECTION: Optimizers & Hyperparameters -->
     <div class="slide">
        <div class="slide-container text-center">
            <p class="slide-part-title">Part 4: Optimizers & Hyperparameters</p>
            <h2 class="slide-title">‚öôÔ∏è Tuning the Engine</h2>
            <p class="slide-subtitle">Finding the right optimizer, learning rate, and batch size.</p>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">The Optimizer Wars: <span class="highlight">AdamW vs. The World</span></h2>
            <p class="slide-subtitle">Which optimizer should you use?</p>
             <div class="slide-content grid grid-cols-1 md:grid-cols-2 gap-8">
                <div>
                    <h3 class="font-bold text-lg">AdamW</h3>
                    <p>The trusty default. It's a first-order optimizer that adapts the learning rate for each parameter. It's stable, well-understood, and used by almost everyone.</p>
                </div>
                 <div>
                    <h3 class="font-bold text-lg">Muon</h3>
                    <p>A second-order optimizer gaining traction in high-profile models (Kimi K2, GLM-4.5). Treats each weight matrix as a single object, potentially capturing better geometry. Can tolerate larger batch sizes but can be less stable.</p>
                </div>
            </div>
            <div class="mt-8 p-4 bg-gray-50 rounded-lg text-center">
                <p><b>Conclusion:</b> While new optimizers are promising, <span class="highlight">AdamW remains the safe, reliable choice for most training runs.</span></p>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Learning Rate Schedules üìà</h2>
            <p class="slide-subtitle">The best learning rate isn't constant. It needs a schedule.</p>
             <div class="slide-content grid grid-cols-1 md:grid-cols-2 gap-8">
                <div>
                    <h3 class="font-bold text-lg">Cosine Decay</h3>
                    <p>The classic schedule. Warmup, peak, then a smooth cosine curve down to a minimum value. It's simple and it works well.</p>
                    <p class="mt-2 text-red-600"><b>Problem:</b> It's inflexible. You must know the total training steps in advance.</p>
                </div>
                 <div>
                    <h3 class="font-bold text-lg">Warmup-Stable-Decay (WSD)</h3>
                    <p>A more flexible alternative. Warmup, then a long stable phase at peak LR, followed by a decay phase (cosine or linear) for the last 10-20% of tokens.</p>
                    <p class="mt-2 text-green-600"><b>Benefit:</b> Allows you to extend training mid-run without restarting. Matches cosine performance while being more practical.</p>
                </div>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Finding the Optimal <span class="highlight">Learning Rate & Batch Size</span></h2>
            <p class="slide-subtitle">A balancing act between speed and data efficiency.</p>
            <div class="slide-content">
                <ul>
                    <li><b>Learning Rate (LR) Sweeps:</b> Run short ablations with different LRs (e.g., 1e-4, 5e-4, 1e-3) to find a sweet spot. Avoid rates that are too high (divergence) or too low (slow convergence).</li>
                    <li><b>Batch Size & Throughput:</b> Increasing batch size improves hardware utilization (throughput). But beyond a "critical batch size," it starts to hurt data efficiency (model needs more tokens to reach the same loss).</li>
                    <li><b>Square-Root Rule:</b> A useful rule of thumb for AdamW is that if you increase the batch size by a factor of <b>k</b>, you should increase the learning rate by a factor of <b>sqrt(k)</b>.</li>
                    <li><b>Scaling Laws:</b> For large-scale training, use scaling laws to predict optimal LR and batch size based on your compute budget, model size, and training tokens.</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- SECTION: Data Curation -->
     <div class="slide">
        <div class="slide-container text-center">
            <p class="slide-part-title">Part 5: The Art of Data Curation</p>
            <h2 class="slide-title">üìö You Are What You Eat</h2>
            <p class="slide-subtitle">Data defines what a model learns. No amount of compute can fix bad data.</p>
        </div>
    </div>
    
     <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">The Evolution of Training <span class="highlight">Curricula</span></h2>
            <p class="slide-subtitle">The data mixture doesn't have to stay fixed.</p>
            <div class="slide-content">
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div>
                        <h3 class="font-bold text-lg">Static Mixture (Old Way)</h3>
                        <p>Models like GPT-3 and early Llamas were trained on a single data mixture from start to finish.</p>
                    </div>
                    <div>
                        <h3 class="font-bold text-lg">Multi-Stage Training (New Way)</h3>
                        <p>The data mixture changes over training. A model's final behavior is strongly influenced by data seen toward the end.</p>
                    </div>
                </div>
                <div class="mt-8 p-6 bg-blue-50 border border-blue-200 rounded-lg">
                    <h3 class="font-bold text-lg text-blue-800">Practical Strategy</h3>
                    <p class="mt-2">Start by training on large, plentiful data sources. Towards the end of training (especially during the LR decay phase), introduce smaller, higher-quality, and more specialized datasets (e.g., for math and code reasoning) to maximize their impact.</p>
                </div>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">SmolLM3's 3-Stage Training Plan</h2>
            <p class="slide-subtitle">A practical example of a multi-stage data curriculum.</p>
            <div class="slide-content space-y-4">
                <div>
                    <h3 class="font-bold text-lg">Stage 1: Base Training (8T tokens)</h3>
                    <p>The foundation stage uses a core mixture of web data (FineWeb-Edu, DCLM), code (The Stack v2), and math (FineMath3+).</p>
                </div>
                <div>
                    <h3 class="font-bold text-lg">Stage 2: High-Quality Injection (2T tokens)</h3>
                    <p>Introduce higher-quality filtered datasets: <span class="highlight">Stack-Edu</span> for code, <span class="highlight">FineMath4+</span> for math, and <span class="highlight">MegaMath</span> for advanced reasoning.</p>
                </div>
                 <div>
                    <h3 class="font-bold text-lg">Stage 3: LR Decay with Reasoning (1.1T tokens)</h3>
                    <p>During the learning rate decay phase, further upsample high-quality code and math, and introduce instruction and reasoning data like <span class="highlight">OpenMathReasoning</span>.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- SECTION: The Training Marathon -->
    <div class="slide">
        <div class="slide-container text-center">
            <p class="slide-part-title">Part 6: The Training Marathon</p>
            <h2 class="slide-title">üèÉ‚Äç‚ôÄÔ∏è It's a Marathon, Not a Sprint</h2>
            <p class="slide-subtitle">Navigating the inevitable surprises of a long training run.</p>
        </div>
    </div>
    
     <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">The Pre-Flight Checklist ‚úÖ</h2>
            <p class="slide-subtitle">What to verify before you hit "train".</p>
            <div class="slide-content">
                <ul class="space-y-3">
                    <li><b>Infrastructure Readiness:</b> Stress-test GPUs (we use GPU Fryer & DCGM) to catch throttling or performance issues before they happen.</li>
                    <li><b>Storage Plan:</b> Ensure your data storage can handle the load. The SmolLM3 run initially suffered from a slow network-attached storage and had to move to fast local storage.</li>
                    <li><b>Automated Evaluations:</b> Manually running evals is a huge bottleneck. Automate them to trigger on every checkpoint.</li>
                    <li><b>Checkpoint & Auto-Resume:</b> Verify that checkpoints are saved correctly (and backed up!) and that the training job can auto-resume from the latest one after a failure.</li>
                    <li><b>Metrics Logging:</b> Confirm you are logging everything you care about: throughput, loss, gradient norm, node health, etc. to a dashboard (e.g., WandB).</li>
                </ul>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Scaling Surprise #1: The Vanishing Throughput üìâ</h2>
            <p class="slide-subtitle">Problem: Within hours of launch, throughput plummeted with sharp drops.</p>
            <div class="slide-content">
                <p><b>Investigation:</b></p>
                <ol class="list-decimal pl-6 mt-2 space-y-2">
                    <li><b>Hardware?</b> Ruled out by reproducing the issue on a single, healthy node.</li>
                    <li><b>Data Storage?</b> Initially, a network storage (FSx) couldn't keep up and was evicting data shards. Moving to local scratch storage helped, but didn't solve it.</li>
                    <li><b>The Culprit: A Dataloader Bug.</b> The dataloader was building a giant index that grew with each training step, causing shared memory issues on very long runs.</li>
                </ol>
                 <div class="mt-6 p-6 bg-green-50 border border-green-200 rounded-lg">
                    <h3 class="font-bold text-lg text-green-800">The Fix</h3>
                    <p class="mt-2">Switched to a more robust, battle-tested dataloader (TokenizedBytes from the SmolLM2 project). The drops were gone and throughput was stable.</p>
                </div>
            </div>
        </div>
    </div>
    
     <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Scaling Surprise #2: Unsatisfactory Performance üò•</h2>
            <p class="slide-subtitle">Problem: At 1T tokens, the new 3B model was performing worse than the old 1.7B model.</p>
             <div class="slide-content">
                <p><b>Investigation:</b></p>
                 <p>After validating every other architecture and data change, only one untested difference remained between the SmolLM2 and SmolLM3 setups: <span class="highlight">Tensor Parallelism (TP)</span>. SmolLM2 didn't need it, but SmolLM3 required TP=2.</p>
                <div class="mt-6 p-6 bg-red-50 border border-red-200 rounded-lg">
                    <h3 class="font-bold text-lg text-red-800">The Culprit: A Subtle TP Bug</h3>
                    <p class="mt-2">We were using the <b>same random seed</b> for weight initialization across all TP ranks. This caused correlated initializations across shards, hurting convergence.</p>
                </div>
                 <div class="mt-6 p-6 bg-green-50 border border-green-200 rounded-lg">
                    <h3 class="font-bold text-lg text-green-800">The Fix</h3>
                    <p class="mt-2">Fixed the code to give each TP rank a different seed (e.g., `seed + tp_rank`). Performance immediately aligned with expectations. The run was restarted after 1T tokens.</p>
                </div>
            </div>
        </div>
    </div>
    
     <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Handling Loss Spikes üî•</h2>
            <p class="slide-subtitle">Those sudden jumps in training loss. When should you worry?</p>
             <div class="slide-content grid grid-cols-1 md:grid-cols-2 gap-8">
                <div>
                    <h3 class="font-bold text-lg">Recoverable Spikes</h3>
                    <p>Usually caused by "bad data" batches. The model recovers either quickly or slowly. You can usually continue training, or rewind to a previous checkpoint to skip the problematic batch.</p>
                </div>
                 <div>
                    <h3 class="font-bold text-lg">Non-Recoverable Spikes</h3>
                    <p>The model diverges or plateaus at a worse performance level. Often caused by high learning rates or poor initialization. These require more significant intervention.</p>
                </div>
            </div>
             <div class="mt-8 p-4 bg-gray-50 rounded-lg">
                <p><b>How to fix:</b> The most common fix is to rewind to a checkpoint before the spike and skip the problematic data batches. The Falcon team skipped 1B tokens to resolve their spikes!</p>
            </div>
        </div>
    </div>
    
    <!-- SECTION: Post-Training -->
    <div class="slide">
        <div class="slide-container text-center">
            <p class="slide-part-title">Part 7: Post-Training</p>
            <h2 class="slide-title">üé® From Raw Ability to Refined Assistant</h2>
            <p class="slide-subtitle">Bridging the gap from a text-predictor to a model people can actually use.</p>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Why (Almost) Every Pipeline Starts with SFT</h2>
            <p class="slide-subtitle">Supervised Fine-Tuning (SFT) is the essential first step in post-training.</p>
            <div class="slide-content">
                <ul class="space-y-4">
                    <li>
                        <b class="text-green-600">It's Cheap:</b> SFT requires modest compute compared to RL and you can get meaningful gains quickly.
                    </li>
                    <li>
                        <b class="text-green-600">It's Stable:</b> Unlike RL, which is notoriously sensitive to hyperparameters, SFT "just works."
                    </li>
                     <li>
                        <b class="text-green-600">It's the Right Baseline:</b> A good SFT checkpoint provides most of the gains and makes later methods like DPO or RLHF much more effective. Base models are often too unrefined to benefit from advanced methods directly.
                    </li>
                </ul>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Picking a Good Chat Template üí¨</h2>
            <p class="slide-subtitle">How you format your data matters. A consistent template is key.</p>
            <div class="slide-content">
                 <p>Before training, you need to unify your datasets into a single format. Key questions to ask:</p>
                <ul class="mt-4 space-y-3">
                    <li><b>System Prompts:</b> Can users customize the system role (e.g., "act like a pirate")?</li>
                    <li><b>Tools:</b> Does the model need to call APIs? The template must support structured outputs for tool calls.</li>
                    <li><b>Reasoning:</b> Does the model need to think step-by-step? Templates like ChatML or Qwen3 support special `<think>` tags.</li>
                    <li><b>Compatibility:</b> Will it work with inference engines like vLLM? Compatibility saves a lot of pain later.</li>
                </ul>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">SFT Hyperparameters That Matter</h2>
            <p class="slide-subtitle">Fine-tuning the fine-tuning process.</p>
            <div class="slide-content">
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div>
                        <h3 class="font-bold text-lg">Masking User Turns</h3>
                        <p>Should the model learn to predict user text? Usually no. By masking the loss on user turns, we focus the model on learning to generate good <span class="highlight">assistant responses</span>.</p>
                    </div>
                    <div>
                        <h3 class="font-bold text-lg">Packing</h3>
                        <p>Concatenating multiple short samples into one sequence dramatically improves training speed (3-5x). But it reduces the number of gradient updates, which can slightly alter learning dynamics on small datasets.</p>
                    </div>
                </div>
                 <div class="mt-8">
                    <h3 class="font-bold text-lg">Learning Rate & Epochs</h3>
                    <p>SFT learning rates are typically 10-100x smaller than pre-training LRs. Unlike pre-training, SFT runs are short, so you can do full sweeps to find the optimal LR. Training for more epochs (e.g., 3-5) can squeeze out more performance.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">From SFT to Preference Optimization üëçüëé</h2>
            <p class="slide-subtitle">Teaching models what "better" means.</p>
            <div class="slide-content">
                <p>SFT is a form of imitation learning. The model only learns to reproduce patterns from its data. To scale beyond this, we need to give it comparative feedback: <span class="highlight">"Response A is better than Response B."</span></p>
                <div class="mt-6">
                    <h3 class="font-bold text-lg">Direct Preference Optimization (DPO)</h3>
                    <p>The default preference algorithm. It's simple, stable, and effective with modest amounts of preference data. It works by increasing the likelihood of the "chosen" response and decreasing the likelihood of the "rejected" one.</p>
                </div>
                <div class="mt-4">
                    <h3 class="font-bold text-lg">Other Algorithms (APO, KTO, ORPO)</h3>
                    <p>Newer methods offer more control or work with different types of feedback (e.g., just "good" or "bad" labels instead of pairs). For SmolLM3, <span class="highlight">Anchored Preference Optimization (APO)</span> gave the best results.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- SECTION: Infrastructure -->
    <div class="slide">
        <div class="slide-container text-center">
            <p class="slide-part-title">Part 8: Infrastructure</p>
            <h2 class="slide-title">üõ†Ô∏è The Unsung Hero</h2>
            <p class="slide-subtitle">Understanding the hardware to identify and fix bottlenecks.</p>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Inside a GPU: Compute & Memory</h2>
            <p class="slide-subtitle">Modern AI is often <span class="highlight">memory-bound</span>, not compute-bound.</p>
            <div class="slide-content">
                 <p>A GPU has two jobs: move data and do work on it. The bottleneck is often moving the data.</p>
                <div class="mt-6">
                    <h3 class="font-bold text-lg">The Memory Hierarchy</h3>
                    <p>GPUs organize memory in a hierarchy from fast-but-small to slow-but-large:</p>
                    <ul class="mt-2 font-mono text-sm">
                        <li><b>Registers:</b> Fastest (~100s TB/s)</li>
                        <li><b>L1/Shared Memory:</b> Fast (~31 TB/s)</li>
                        <li><b>L2 Cache:</b> Medium (~13 TB/s)</li>
                        <li><b>HBM (Main Memory):</b> Slowest (~3 TB/s)</li>
                    </ul>
                    <p class="mt-2"><b>Key Principle:</b> Minimize traffic to slow memory (HBM) and maximize use of fast memory (SRAM caches, registers). This is why techniques like <b>Flash Attention</b> are so effective.</p>
                </div>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">GPU Communication: The Bottleneck Stack</h2>
            <p class="slide-subtitle">Bandwidth decreases dramatically as we move further from the GPU.</p>
             <div class="slide-content">
                <p>Understanding communication links is key to identifying bottlenecks in distributed training.</p>
                <ul class="mt-4 space-y-3">
                    <li>‚ö°Ô∏è <b>Intra-Node (GPU-GPU):</b> Uses <b>NVLink</b>, a high-speed direct interconnect. On H100s, this provides ~786 GB/s bidirectional bandwidth. This is incredibly fast.</li>
                    <li>‚ÜîÔ∏è <b>Inter-Node (Network):</b> Uses network interfaces like InfiniBand or Ethernet (EFA on AWS). This drops bandwidth to ~42 GB/s for point-to-point communication.</li>
                    <li>üêå <b>CPU-GPU:</b> Uses <b>PCIe</b> connections. This is often the slowest link, bottlenecking at ~14.2 GB/s in the benchmarked system. Avoid if possible!</li>
                    <li>üíæ <b>GPU-Storage:</b> Can be a bottleneck for data loading and checkpointing. Use fast local storage (NVMe RAID) for best performance.</li>
                </ul>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">How Many GPUs Do I Need? üßÆ</h2>
            <p class="slide-subtitle">A simple formula to estimate your hardware needs.</p>
            <div class="slide-content text-center">
                <div class="p-6 bg-gray-100 rounded-lg inline-block text-lg">
                    <p><b>GPU Count = Total FLOPs Required / (Per-GPU Throughput √ó Target Training Time)</b></p>
                </div>
                <div class="mt-8 text-left">
                    <p><b>1. Total FLOPs Required:</b> ~6 √ó Model Parameters √ó Training Tokens.</p>
                    <p class="mt-2"><b>2. Per-GPU Throughput:</b> This is where reality hits. You need to estimate your <b>Model FLOPs Utilization (MFU)</b>, the percentage of theoretical peak performance you actually achieve. State-of-the-art is often 20-40%.</p>
                     <p class="mt-2"><b>3. Target Training Time:</b> How long you're willing to wait.</p>
                </div>
            </div>
        </div>
    </div>
    
    <div class="slide">
        <div class="slide-container">
            <h2 class="slide-title">Why More GPUs Isn't Always Better: <span class="highlight">Amdahl's Law</span></h2>
            <p class="slide-subtitle">Speedup from parallelization is limited by the serial part of the workload.</p>
            <div class="slide-content">
                <p>In LLM training, the "serial" portion is primarily <b>communication overhead</b> (synchronizing gradients). As you add more GPUs, the proportion of time spent on communication increases, leading to diminishing returns in speedup and lower per-GPU efficiency.</p>
                <div class="mt-6 p-6 bg-yellow-50 border border-yellow-300 rounded-lg">
                    <p>If communication takes 10% of each training step, then no matter how many GPUs you add, you'll never get more than a <b>10x speedup.</b></p>
                </div>
            </div>
        </div>
    </div>

    <!-- Conclusion -->
    <div class="slide">
        <div class="slide-container text-center">
            <div class="text-6xl mb-6">üéØ</div>
            <h2 class="slide-title">Final Conclusion: Core Insights</h2>
            <div class="slide-content max-w-4xl mx-auto">
                <p class="mb-4">Training world-class LLMs is a systematic process of <span class="highlight">planning, ablation, monitoring, and debugging.</span></p>
                 <ul class="text-left mt-8 space-y-3">
                    <li><b>Validate everything</b> through experiments. Don't trust intuition alone.</li>
                    <li><b>Change one thing at a time</b> to understand its impact.</li>
                    <li><b>Expect scale to break things</b> in new and surprising ways.</li>
                    <li><b>Let your use case drive decisions</b>, not the hype from the latest paper.</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- Thank You / Q&A -->
    <div class="slide">
        <div class="slide-container text-center">
            <div class="text-7xl mb-8">üëè</div>
            <h1 class="text-5xl md:text-6xl font-bold text-gray-800 mb-4">Thank You</h1>
            <p class="text-xl md:text-2xl text-gray-600">Q&A</p>
            <p class="mt-8 text-gray-500">May the force of open source and open science always be with you!</p>
        </div>
    </div>

  </div>

  <!-- Navigation -->
  <div class="progress-bar-container">
    <div class="progress-bar">
      <div id="progress" class="progress"></div>
    </div>
    <div class="flex justify-between items-center w-full max-w-6xl mx-auto">
      <button id="prevBtn" class="btn btn-secondary"><i class="fa-solid fa-arrow-left mr-2"></i> Previous</button>
      <span id="slideCounter" class="text-gray-600 font-medium"></span>
      <button id="nextBtn" class="btn btn-primary">Next <i class="fa-solid fa-arrow-right ml-2"></i></button>
    </div>
  </div>

  <script>
    let currentSlide = 0;
    const slides = document.querySelectorAll('.slide');
    const slideCounter = document.getElementById('slideCounter');
    const prevBtn = document.getElementById('prevBtn');
    const nextBtn = document.getElementById('nextBtn');
    const progressBar = document.getElementById('progress');

    function updateSlide() {
      slides.forEach((slide, index) => {
        slide.classList.remove('active');
        if (index === currentSlide) {
          slide.classList.add('active');
        }
      });
      slideCounter.textContent = `Slide ${currentSlide + 1} / ${slides.length}`;
      progressBar.style.width = `${((currentSlide + 1) / slides.length) * 100}%`;

      prevBtn.disabled = currentSlide === 0;
      nextBtn.disabled = currentSlide === slides.length - 1;

      prevBtn.classList.toggle('opacity-50', currentSlide === 0);
      prevBtn.classList.toggle('cursor-not-allowed', currentSlide === 0);
      nextBtn.classList.toggle('opacity-50', currentSlide === slides.length - 1);
      nextBtn.classList.toggle('cursor-not-allowed', currentSlide === slides.length - 1);
    }

    nextBtn.addEventListener('click', () => {
      if (currentSlide < slides.length - 1) {
        currentSlide++;
        updateSlide();
      }
    });

    prevBtn.addEventListener('click', () => {
      if (currentSlide > 0) {
        currentSlide--;
        updateSlide();
      }
    });

    document.addEventListener('keydown', (e) => {
      if (e.key === 'ArrowRight' || e.key === ' ') {
        e.preventDefault();
        nextBtn.click();
      } else if (e.key === 'ArrowLeft') {
        e.preventDefault();
        prevBtn.click();
      }
    });

    // Initial setup
    updateSlide();
  </script>


<script data-reading-archive-scroll-nav>
(function () {
  function findButton(selectors) {
    for (var i = 0; i < selectors.length; i += 1) {
      var el = document.querySelector(selectors[i]);
      if (el) return el;
    }
    return null;
  }

  var nextBtn = findButton(['[data-reading-archive-next]', '[data-slide-next]', '#nextBtn', '.next-slide']);
  var prevBtn = findButton(['[data-reading-archive-prev]', '[data-slide-prev]', '#prevBtn', '.prev-slide']);
  var hasButtonNav = !!(nextBtn || prevBtn);

  function collectSections() {
    var nodes = document.querySelectorAll('.slide, [data-slide], section');
    var list = Array.prototype.slice.call(nodes || []);
    var result = [];
    for (var i = 0; i < list.length; i += 1) {
      var node = list[i];
      if (!node) continue;
      var duplicate = false;
      for (var j = 0; j < result.length; j += 1) {
        if (result[j] === node) {
          duplicate = true;
          break;
        }
      }
      if (duplicate) continue;
      var style = window.getComputedStyle ? window.getComputedStyle(node) : null;
      var visible = node.offsetHeight > 0 && (!style || style.visibility !== 'hidden');
      if (visible) result.push(node);
    }
    return result;
  }

  function buildSectionNavigator(elements) {
    if (!elements || elements.length <= 1) return null;
    var index = 0;
    var animating = false;

    function clamp(value) {
      if (value < 0) return 0;
      if (value > elements.length - 1) return elements.length - 1;
      return value;
    }

    function syncIndex() {
      var best = index;
      var bestDist = Infinity;
      for (var i = 0; i < elements.length; i += 1) {
        var rect = elements[i].getBoundingClientRect();
        var dist = Math.abs(rect.top);
        if (dist < bestDist) {
          bestDist = dist;
          best = i;
        }
      }
      index = best;
    }

    function smoothScroll(target) {
      var top = window.scrollY + target.getBoundingClientRect().top;
      if (typeof window.scrollTo === 'function') {
        try {
          window.scrollTo({ top: top, behavior: 'smooth' });
        } catch (err) {
          window.scrollTo(0, top);
        }
      } else {
        document.documentElement.scrollTop = top;
        document.body.scrollTop = top;
      }
    }

    function scrollToIndex(next) {
      next = clamp(next);
      if (next === index) return false;
      animating = true;
      index = next;
      smoothScroll(elements[index]);
      setTimeout(function () {
        animating = false;
      }, 420);
      return true;
    }

    window.addEventListener('resize', syncIndex);

    return {
      move: function (step) {
        if (animating) return false;
        syncIndex();
        return scrollToIndex(index + step);
      },
    };
  }

  var sectionNav = null;
  if (!hasButtonNav) {
    sectionNav = buildSectionNavigator(collectSections());
  }
  var hasAnyNavigation = hasButtonNav || !!sectionNav;
  if (!hasAnyNavigation) return;

  var lock = false;
  var lockTimer = null;

  function armLock() {
    lock = true;
    clearTimeout(lockTimer);
    lockTimer = setTimeout(function () {
      lock = false;
    }, 420);
  }

  function canUseButton(btn) {
    if (!btn) return false;
    if (typeof btn.disabled === 'boolean' && btn.disabled) return false;
    var aria = btn.getAttribute ? btn.getAttribute('aria-disabled') : null;
    if (aria && aria.toLowerCase() === 'true') return false;
    return true;
  }

  function trigger(step) {
    if (!step || lock) return;
    var handled = false;
    if (step > 0) {
      if (canUseButton(nextBtn)) {
        nextBtn.click();
        handled = true;
      } else if (sectionNav && sectionNav.move(1)) {
        handled = true;
      }
    } else if (step < 0) {
      if (canUseButton(prevBtn)) {
        prevBtn.click();
        handled = true;
      } else if (sectionNav && sectionNav.move(-1)) {
        handled = true;
      }
    }
    if (handled) {
      armLock();
    }
  }

  window.addEventListener('wheel', function (event) {
    if (Math.abs(event.deltaY) < 24) return;
    event.preventDefault();
    trigger(event.deltaY);
  }, { passive: false });

  if (!hasButtonNav && sectionNav) {
    window.addEventListener('keydown', function (event) {
      if (['ArrowDown', 'PageDown', ' ', 'Spacebar'].indexOf(event.key) !== -1) {
        event.preventDefault();
        trigger(1);
      } else if (['ArrowUp', 'PageUp'].indexOf(event.key) !== -1) {
        event.preventDefault();
        trigger(-1);
      }
    });
  }

  var touchStartY = null;
  var touchStartX = null;

  window.addEventListener('touchstart', function (event) {
    if (event.touches.length !== 1) return;
    touchStartY = event.touches[0].clientY;
    touchStartX = event.touches[0].clientX;
  }, { passive: true });

  window.addEventListener('touchend', function (event) {
    if (touchStartY === null) return;
    var touch = event.changedTouches[0];
    var dy = touchStartY - touch.clientY;
    var dx = touchStartX - touch.clientX;
    touchStartY = null;
    touchStartX = null;
    if (Math.abs(dy) < 40 || Math.abs(dy) < Math.abs(dx)) return;
    trigger(dy);
  }, { passive: true });

  window.addEventListener('touchcancel', function () {
    touchStartY = null;
    touchStartX = null;
  }, { passive: true });
})();
</script>
</body>
</html>